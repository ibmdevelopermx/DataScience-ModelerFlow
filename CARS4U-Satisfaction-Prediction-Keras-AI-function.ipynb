{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"border: none\" align=\"left\">\n    <tr style=\"border: none\">\n       <th style=\"border: none\"><img src=\"https://raw.githubusercontent.com/pmservice/cars-4-you/master/static/images/logo.png\" width=\"200\" alt=\"Icon\"></th>\n       <th style=\"border: none\"><font face=\"verdana\" size=\"5\" color=\"black\"><b>Customer Satisfaction Prediction</b></th>\n   </tr>\n</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=left src=\"https://github.com/pmservice/cars-4-you/raw/master/static/images/ai_function.png\" alt=\"Icon\" width=\"664\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras model and AI function to determine if comment is a complain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contents\n",
    "\n",
    "- [0. Setup](#setup)\n",
    "- [1. Introduction](#introduction)\n",
    "- [2. Load and explore data](#load)\n",
    "- [3. Create Keras model using TensorFlow backend](#model)\n",
    "- [4. Store the model in the repository](#persistence)\n",
    "- [5. Deploy the model](#deployment)\n",
    "- [6. AI function](#ai_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"setup\"></a>\n## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install TensorFlow version 1.5 and newest version of watson-machine-learning-client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: tensorflow==1.5 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages\nRequirement not upgraded as not directly required: six>=1.10.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from tensorflow==1.5)\nRequirement not upgraded as not directly required: numpy>=1.12.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from tensorflow==1.5)\nRequirement not upgraded as not directly required: protobuf>=3.4.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from tensorflow==1.5)\nRequirement not upgraded as not directly required: tensorflow-tensorboard<1.6.0,>=1.5.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from tensorflow==1.5)\nRequirement not upgraded as not directly required: absl-py>=0.1.6 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from tensorflow==1.5)\nRequirement not upgraded as not directly required: wheel>=0.26 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from tensorflow==1.5)\nRequirement not upgraded as not directly required: setuptools in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from protobuf>=3.4.0->tensorflow==1.5)\nRequirement not upgraded as not directly required: werkzeug>=0.11.10 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5)\nRequirement not upgraded as not directly required: bleach==1.5.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5)\nRequirement not upgraded as not directly required: html5lib==0.9999999 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5)\nRequirement not upgraded as not directly required: markdown>=2.6.8 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from tensorflow-tensorboard<1.6.0,>=1.5.0->tensorflow==1.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade tensorflow==1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: watson-machine-learning-client in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages\nRequirement not upgraded as not directly required: urllib3 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement not upgraded as not directly required: tqdm in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement not upgraded as not directly required: lomond in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement not upgraded as not directly required: requests in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement not upgraded as not directly required: tabulate in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement not upgraded as not directly required: ibm-cos-sdk in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement not upgraded as not directly required: pandas in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement not upgraded as not directly required: certifi in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from watson-machine-learning-client)\nRequirement not upgraded as not directly required: six>=1.10.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from lomond->watson-machine-learning-client)\nRequirement not upgraded as not directly required: chardet<3.1.0,>=3.0.2 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from requests->watson-machine-learning-client)\nRequirement not upgraded as not directly required: idna<2.7,>=2.5 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from requests->watson-machine-learning-client)\nRequirement not upgraded as not directly required: ibm-cos-sdk-s3transfer==2.*,>=2.0.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client)\nRequirement not upgraded as not directly required: ibm-cos-sdk-core==2.*,>=2.0.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk->watson-machine-learning-client)\nRequirement not upgraded as not directly required: python-dateutil>=2 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pandas->watson-machine-learning-client)\nRequirement not upgraded as not directly required: pytz>=2011k in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pandas->watson-machine-learning-client)\nRequirement not upgraded as not directly required: numpy>=1.9.0 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from pandas->watson-machine-learning-client)\nRequirement not upgraded as not directly required: docutils>=0.10 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client)\nRequirement not upgraded as not directly required: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages (from ibm-cos-sdk-core==2.*,>=2.0.0->ibm-cos-sdk->watson-machine-learning-client)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf $PIP_BUILD/watson-machine-learning-client\n",
    "!pip install --upgrade --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.python.org/simple/ watson-machine-learning-client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WML Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [],
   "source": [
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TIP:** Put your Watson Machine Learning credentials here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "\n",
    "wml_credentials = {\n",
    "  \"apikey\": \"***\",\n",
    "  \"instance_id\": \"***\",\n",
    "  \"password\": \"***\",\n",
    "  \"url\": \"https://us-south.ml.cloud.ibm.com\",\n",
    "  \"username\": \"***\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting model: dc8aa4b5-1eb6-4f79-b6d2-bdcf946d95ef\n"
     ]
    }
   ],
   "source": [
    "for r in client.repository.get_model_details()['resources']:\n",
    "    if r['entity']['name'] == 'CARS4U - Satisfaction Prediction Model':\n",
    "        guid_to_delete = r['metadata']['guid']\n",
    "        print('Deleting model: ' + str(guid_to_delete))\n",
    "        client.repository.delete(guid_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting function: 2fecc619-44a7-4c5d-8384-c043ee80e16e\nDeleting orphaned function deployment '5c794152-150c-4a2d-9369-4b9b881c6d8f'... SUCCESS\n"
     ]
    }
   ],
   "source": [
    "for r in client.repository.get_function_details()['resources']:\n",
    "    if r['entity']['name'] == 'CARS4U - Satisfaction Prediction - AI Function':\n",
    "        guid_to_delete = r['metadata']['guid']\n",
    "        print('Deleting function: ' + str(guid_to_delete))\n",
    "        client.repository.delete(guid_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in client.deployments.get_details()['resources']:\n",
    "    if r['entity']['name'] == 'CARS4U - Satisfaction Prediction - AI Function Deployment':\n",
    "        guid_to_delete = r['metadata']['guid']\n",
    "        print('Deleting function deployment: ' + str(guid_to_delete))\n",
    "        client.deployments.delete(guid_to_delete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"introduction\"></a>\n## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook trains a **Keras** (TensorFlow) model to predict customer satisfaction based on provided feedback. Notebook also shows usage of **AI Function** for deep learning model data preprocessing required before model scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load\"></a>\n## 2. Load and explore data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the data is loaded as pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/ibmdbpy/utils.py:238: UserWarning: Mixed case names are not supported in database object names.\n  warnings.warn(\"Mixed case names are not supported in database object names.\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Gender</th>\n      <th>Status</th>\n      <th>Children</th>\n      <th>Age</th>\n      <th>Customer_Status</th>\n      <th>Car_Owner</th>\n      <th>Customer_Service</th>\n      <th>Satisfaction</th>\n      <th>Business_Area</th>\n      <th>Action</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>74</td>\n      <td>Male</td>\n      <td>M</td>\n      <td>1</td>\n      <td>26.26</td>\n      <td>Active</td>\n      <td>No</td>\n      <td>no wait for pick up and drop off was great, he...</td>\n      <td>1</td>\n      <td>Product: Information</td>\n      <td>NA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>83</td>\n      <td>Female</td>\n      <td>M</td>\n      <td>2</td>\n      <td>48.85</td>\n      <td>Inactive</td>\n      <td>Yes</td>\n      <td>I thought the representative handled the initi...</td>\n      <td>0</td>\n      <td>Product: Availability/Variety/Size</td>\n      <td>Free Upgrade</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>140</td>\n      <td>Female</td>\n      <td>S</td>\n      <td>0</td>\n      <td>36.92</td>\n      <td>Inactive</td>\n      <td>No</td>\n      <td>Everyone was very cooperative.  The auto was r...</td>\n      <td>1</td>\n      <td>Product: Functioning</td>\n      <td>NA</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>191</td>\n      <td>Male</td>\n      <td>M</td>\n      <td>0</td>\n      <td>45.51</td>\n      <td>Inactive</td>\n      <td>Yes</td>\n      <td>what customer service? It was a nightmare</td>\n      <td>0</td>\n      <td>Service: Knowledge</td>\n      <td>Voucher</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>239</td>\n      <td>Male</td>\n      <td>M</td>\n      <td>1</td>\n      <td>46.00</td>\n      <td>Inactive</td>\n      <td>Yes</td>\n      <td>They did not have the auto I wanted.  upgraded...</td>\n      <td>0</td>\n      <td>Product: Availability/Variety/Size</td>\n      <td>Free Upgrade</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
      ],
      "text/plain": [
       "    ID  Gender Status  Children    Age Customer_Status Car_Owner  \\\n0   74    Male      M         1  26.26          Active        No   \n1   83  Female      M         2  48.85        Inactive       Yes   \n2  140  Female      S         0  36.92        Inactive        No   \n3  191    Male      M         0  45.51        Inactive       Yes   \n4  239    Male      M         1  46.00        Inactive       Yes   \n\n                                    Customer_Service  Satisfaction  \\\n0  no wait for pick up and drop off was great, he...             1   \n1  I thought the representative handled the initi...             0   \n2  Everyone was very cooperative.  The auto was r...             1   \n3          what customer service? It was a nightmare             0   \n4  They did not have the auto I wanted.  upgraded...             0   \n\n                        Business_Area        Action  \n0                Product: Information            NA  \n1  Product: Availability/Variety/Size  Free Upgrade  \n2                Product: Functioning            NA  \n3                  Service: Knowledge       Voucher  \n4  Product: Availability/Variety/Size  Free Upgrade  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from ibmdbpy import IdaDataBase, IdaDataFrame\n",
    "\n",
    "# @hidden_cell\n",
    "# This connection object is used to access your data and contains your credentials.\n",
    "# Replace the dsn and username credentials in the two line below with those from your Db2 Warehouse instance:\n",
    "dsn = 'Database=BLUDB;Hostname=dashdb-entry-yp-dal10-01.services.dal.bluemix.net;Port=50000;PROTOCOL=TCPIP;UID=dash8244;PWD=e12a457b0b2b;'\n",
    "username = 'dash8244'\n",
    "\n",
    "dsn_combined = 'DASHDB;' + dsn\n",
    "idadb_c166344e776040b39f477655199897f8 = IdaDataBase(dsn=dsn_combined)\n",
    "\n",
    "data_df = IdaDataFrame(idadb_c166344e776040b39f477655199897f8, username + '.CAR_RENTAL_TRAINING').as_dataframe()\n",
    "data_df.head()\n",
    "\n",
    "# You can close the database connection with the following code. Please keep the comment line with the @hidden_cell tag,\n",
    "# because the close function displays parts of the credentials.\n",
    "# @hidden_cell\n",
    "# idadb_c166344e776040b39f477655199897f8.close()\n",
    "# To learn more about the ibmdby package, please read the documentation: http://pythonhosted.org/ibmdbpy/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** 0 - not satisfied, 1 - satisfied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract needed columns and count number of records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "complain_data = data_df[['Customer_Service', 'Satisfaction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer_Service    482\nSatisfaction        482\ndtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(complain_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"model\"></a>\n## 3. Create Keras model using TensorFlow backend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(482, 50)\n"
     ]
    }
   ],
   "source": [
    "max_fatures = 500\n",
    "\n",
    "for idx,row in complain_data.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(complain_data['Customer_Service'].values)\n",
    "X = tokenizer.texts_to_sequences(complain_data['Customer_Service'].values)\n",
    "\n",
    "maxlen = 50\n",
    "\n",
    "X = pad_sequences(X, maxlen=maxlen)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(322, 50) (322,)\n(160, 50) (160,)\n"
     ]
    }
   ],
   "source": [
    "Y = complain_data['Satisfaction'].values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.33, random_state = 42)\n",
    "\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Design and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the network definition based on Gated Recurrent Unit (Cho et al. 2014)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_13 (Embedding)     (None, 50, 32)            16000     \n_________________________________________________________________\nconv1d_13 (Conv1D)           (None, 50, 32)            3104      \n_________________________________________________________________\nmax_pooling1d_13 (MaxPooling (None, 25, 32)            0         \n_________________________________________________________________\nlstm_13 (LSTM)               (None, 100)               53200     \n_________________________________________________________________\ndense_13 (Dense)             (None, 1)                 101       \n=================================================================\nTotal params: 72,405\nTrainable params: 72,405\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_fatures, embedding_vector_length, input_length=maxlen))\n",
    "model.add(Conv1D(filters=32, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 322 samples, validate on 160 samples\nEpoch 1/20\n322/322 [==============================] - 3s 9ms/step - loss: 0.6882 - acc: 0.5497 - val_loss: 0.6847 - val_acc: 0.5500\nEpoch 2/20\n322/322 [==============================] - 1s 3ms/step - loss: 0.6743 - acc: 0.5776 - val_loss: 0.6853 - val_acc: 0.5500\nEpoch 3/20\n322/322 [==============================] - 1s 3ms/step - loss: 0.6697 - acc: 0.5776 - val_loss: 0.6849 - val_acc: 0.5500\nEpoch 4/20\n322/322 [==============================] - 1s 4ms/step - loss: 0.6554 - acc: 0.5776 - val_loss: 0.6843 - val_acc: 0.5500\nEpoch 5/20\n322/322 [==============================] - 1s 3ms/step - loss: 0.6463 - acc: 0.5776 - val_loss: 0.6825 - val_acc: 0.5500\nEpoch 6/20\n322/322 [==============================] - 1s 3ms/step - loss: 0.6249 - acc: 0.6087 - val_loss: 0.6463 - val_acc: 0.6375\nEpoch 7/20\n322/322 [==============================] - 1s 3ms/step - loss: 0.5879 - acc: 0.7453 - val_loss: 0.6134 - val_acc: 0.6500\nEpoch 8/20\n322/322 [==============================] - 1s 4ms/step - loss: 0.5553 - acc: 0.7764 - val_loss: 0.5694 - val_acc: 0.6937\nEpoch 9/20\n322/322 [==============================] - 1s 4ms/step - loss: 0.4939 - acc: 0.7981 - val_loss: 0.5279 - val_acc: 0.7250\nEpoch 10/20\n322/322 [==============================] - 1s 5ms/step - loss: 0.4252 - acc: 0.8230 - val_loss: 0.5382 - val_acc: 0.6875\nEpoch 11/20\n322/322 [==============================] - 1s 3ms/step - loss: 0.3893 - acc: 0.8354 - val_loss: 0.4139 - val_acc: 0.8500\nEpoch 12/20\n322/322 [==============================] - 1s 3ms/step - loss: 0.3241 - acc: 0.9099 - val_loss: 0.3605 - val_acc: 0.8438\nEpoch 13/20\n322/322 [==============================] - 1s 3ms/step - loss: 0.2223 - acc: 0.9441 - val_loss: 0.3121 - val_acc: 0.9000\nEpoch 14/20\n322/322 [==============================] - 1s 3ms/step - loss: 0.1823 - acc: 0.9658 - val_loss: 0.2852 - val_acc: 0.9125\nEpoch 15/20\n322/322 [==============================] - 1s 3ms/step - loss: 0.1589 - acc: 0.9658 - val_loss: 0.2566 - val_acc: 0.9062\nEpoch 16/20\n322/322 [==============================] - 1s 3ms/step - loss: 0.1202 - acc: 0.9720 - val_loss: 0.2401 - val_acc: 0.8938\nEpoch 17/20\n322/322 [==============================] - 1s 4ms/step - loss: 0.0967 - acc: 0.9689 - val_loss: 0.2437 - val_acc: 0.9000\nEpoch 18/20\n322/322 [==============================] - 1s 4ms/step - loss: 0.0786 - acc: 0.9752 - val_loss: 0.2611 - val_acc: 0.9250\nEpoch 19/20\n322/322 [==============================] - 1s 3ms/step - loss: 0.0651 - acc: 0.9752 - val_loss: 0.2810 - val_acc: 0.9313\nEpoch 20/20\n322/322 [==============================] - 1s 4ms/step - loss: 0.0556 - acc: 0.9752 - val_loss: 0.2993 - val_acc: 0.9187\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=20, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy on test: 0.931\n"
     ]
    }
   ],
   "source": [
    "print(\"Best accuracy on test: %3.3f\" % numpy.array(history.history['val_acc']).max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** For purpose of this demo model tuning has been skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store and archive the model on notebook filesystem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Accuracy: 91.88%\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"Evaluation Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'complain_model.h5'\n",
    "model.save(filename)\n",
    "\n",
    "#compress keras model\n",
    "tar_filename = filename + \".tgz\"\n",
    "cmdstring = \"tar -zcvf \" + tar_filename + \" \" + filename\n",
    "os.system(cmdstring);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1692\r\n-rw-r----- 1 dsxuser dsxuser 816573 Aug 10 20:46 complain_model.h5.tgz\r\n-rw-r----- 1 dsxuser dsxuser 904032 Aug 10 20:46 complain_model.h5\r\ndrwxr-x--- 2 dsxuser dsxuser   4096 Aug 10 20:45 .\r\ndrwx------ 1 dsxuser dsxuser   4096 Aug 10 19:13 ..\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"persistence\"></a>\n## 4. Store the model in the repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_props = {\n",
    "    client.repository.ModelMetaNames.NAME: \"CARS4U - Satisfaction Prediction Model\",\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_NAME: \"tensorflow\",\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_VERSION: \"1.5\",\n",
    "    client.repository.ModelMetaNames.RUNTIME_NAME: \"python\",\n",
    "    client.repository.ModelMetaNames.RUNTIME_VERSION: \"3.5\",\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_LIBRARIES: [{'name':'keras', 'version': '2.1.3'}]\n",
    "}\n",
    "\n",
    "published_model_details = client.repository.store_model(model=tar_filename, meta_props=model_props)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69039dc1-7551-4e59-b5d8-76c8f9bfb33f\n"
     ]
    }
   ],
   "source": [
    "model_uid = client.repository.get_model_uid(published_model_details)\n",
    "print(model_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"deployment\"></a>\n## 5. Deploy the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Create deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '69039dc1-7551-4e59-b5d8-76c8f9bfb33f' started\n\n#######################################################################################\n\n\nINITIALIZING\nDEPLOY_IN_PROGRESS..\nDEPLOY_SUCCESS\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='0d23f84e-0dad-4f96-b76d-3f3fa7eddca6'\n------------------------------------------------------------------------------------------------\n\n\n"
     ]
    }
   ],
   "source": [
    "deployment = client.deployments.create(model_uid, 'CARS4U - Satisfaction Prediction Model Deployment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  ---------------------------------------------------------------------  ------  --------------  ------------------------  --------------  -------------\nGUID                                  NAME                                                                   TYPE    STATE           CREATED                   FRAMEWORK       ARTIFACT TYPE\n0d23f84e-0dad-4f96-b76d-3f3fa7eddca6  CARS4U - Satisfaction Prediction Model Deployment                      online  DEPLOY_SUCCESS  2018-08-10T20:46:49.145Z  tensorflow-1.5  model\na51a851b-eec5-4add-b587-5cc3e38e7983  CARS4U - Business area and Action Prediction - AI Function Deployment  online  DEPLOY_SUCCESS  2018-08-10T20:44:30.697Z  n/a             function\na4a64eb9-5cdf-4829-985c-6593d23166c9  CARS4U - Business Area Prediction Model Deployment                     online  DEPLOY_SUCCESS  2018-08-10T20:42:10.217Z  mllib-2.1       model\n2fb98bac-2b7f-48ee-a5af-21b060d60fdb  CARS4U - Action Model Deployment                                       online  DEPLOY_SUCCESS  2018-08-10T20:40:20.278Z  mllib-2.1       model\n------------------------------------  ---------------------------------------------------------------------  ------  --------------  ------------------------  --------------  -------------\n"
     ]
    }
   ],
   "source": [
    "client.deployments.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Score the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if our deployment works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_endpoint = client.deployments.get_scoring_url(deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://us-south.ml.cloud.ibm.com/v3/wml_instances/1e60cd60-afdd-4caa-b37a-b028116820ff/deployments/0d23f84e-0dad-4f96-b76d-3f3fa7eddca6/online\n"
     ]
    }
   ],
   "source": [
    "print(scoring_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n   0   0   0   0   0   0   0  40 107 131  19   1  22  77]\n0\n"
     ]
    }
   ],
   "source": [
    "index = 5\n",
    "\n",
    "scoring_data = X[index].tolist()\n",
    "print(X_test[index])\n",
    "print(Y_test[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_payload = {'values': [scoring_data]}\n",
    "scores = client.deployments.score(scoring_endpoint, scoring_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'values': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 266, 138, 139, 267, 207, 115, 12, 8]]}\n"
     ]
    }
   ],
   "source": [
    "print(scoring_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 584,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scoring_payload['values'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'values': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 266, 138, 139, 267, 207, 115, 12, 8], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 2, 78, 5, 7, 13, 122, 3, 109, 51, 0, 0, 58, 15, 808, 31, 7, 23]]}\n"
     ]
    }
   ],
   "source": [
    "print({'values': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 266, 138, 139, 267, 207, 115, 12, 8], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10, 2, 78, 5, 7, 13, 122, 3, 109, 51, 0, 0, 58, 15, 808, 31, 7, 23]]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's print scoring results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fields': ['prediction', 'prediction_classes', 'probability'], 'values': [[[0.002137536881491542], [0], [0.002137536881491542]]]}\n"
     ]
    }
   ],
   "source": [
    "print(str(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"function\"></a>\n## 6. AI function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define AI function that does data preprocessing and model scoring for us. As noticed above model expects numerical input, so the text comment needs to be preprocessed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some generic parameters our function will use to score the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_params = {\n",
    "    'scoring_endpoint': scoring_endpoint,\n",
    "    'wml_credentials': wml_credentials,\n",
    "    'word_index': tokenizer.word_index,\n",
    "    'nlu_url': 'https://gateway.watsonplatform.net/natural-language-understanding/api/v1/analyze?version=2018-03-19',\n",
    "    'nlu_username': '5c3be8c8-5932-4abe-bb39-7e7167602ccc',\n",
    "    'nlu_password': 'cB4AYGkDB6rA'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_generator(params=ai_params):\n",
    "\n",
    "    def score_nlu(text):\n",
    "        import requests\n",
    "\n",
    "        payload = {\"text\": text, \"features\": {\"sentiment\": {}, \"keywords\": {} }}\n",
    "        header = {\"Content-Type\":\"application/json\"}\n",
    "        response_post = requests.post(params['nlu_url'], json=payload, headers=header, auth=(params['nlu_username'], params['nlu_password']))\n",
    "\n",
    "        return(response_post.json()['sentiment']['document'])\n",
    "\n",
    "    def score(payload):\n",
    "        import re\n",
    "        from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "        client = WatsonMachineLearningAPIClient(params['wml_credentials'])\n",
    "        \n",
    "        max_fatures = 500\n",
    "        maxlen = 50\n",
    "\n",
    "        complain_data = payload['values']\n",
    "        word_index = params['word_index']\n",
    "        values = []\n",
    "        \n",
    "        for data in complain_data:\n",
    "            comment = data[0]\n",
    "            \n",
    "            if len(comment) < 16:\n",
    "                cleanString = re.sub(r\"[!\\\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~]\", \"\", comment)\n",
    "                splitted_comment = cleanString.split()[:maxlen]\n",
    "                hashed_tokens = []\n",
    "\n",
    "                for token in splitted_comment:\n",
    "                    index = word_index.get(token, 0)\n",
    "                    if index < 501 and index > 0:\n",
    "                        hashed_tokens.append(index)\n",
    "\n",
    "                hashed_tokens_size = len(hashed_tokens)\n",
    "                padded_tokens = [0]*(maxlen-hashed_tokens_size) + hashed_tokens\n",
    "\n",
    "                score_result = client.deployments.score(params['scoring_endpoint'], {'values':[padded_tokens]})\n",
    "                values.append(score_result['values'][0])\n",
    "            else:\n",
    "                score_result = score_nlu(comment)\n",
    "                score = score_result['score']\n",
    "                predicted_class = score_result['label']\n",
    "            \n",
    "                if predicted_class == 'positive':\n",
    "                    values.append([[score], [1], [score]])\n",
    "                elif predicted_class == 'neutral':\n",
    "                    values.append([[0.5 - score], [0], [0.5 - score]])\n",
    "                else:\n",
    "                    values.append([[score*-1], [0], [score*-1]])\n",
    "        \n",
    "        fields = ['prediction', 'prediction_classes', 'probability']\n",
    "\n",
    "        return {'fields': fields, 'values': values}\n",
    "        \n",
    "        \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = {\n",
    "    'fields': ['feedback'],\n",
    "    'values': [\n",
    "        ['delayed shuttle, almost missed flight, bad customer service'],\n",
    "        ['The car was great and they were able to provide all features I wanted with limited time they had.'],\n",
    "        ['The car was terrible but the service was good.'],\n",
    "        ['I hate cars4you'],\n",
    "        ['I love it.']\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fields': ['prediction', 'prediction_classes', 'probability'],\n 'values': [[[0.877637], [0], [0.877637]],\n  [[0.623983], [1], [0.623983]],\n  [[0.5], [0], [0.5]],\n  [[0.4733937978744507], [0], [0.4733937978744507]],\n  [[0.7068807482719421], [1], [0.7068807482719421]]]}"
      ]
     },
     "execution_count": 590,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = score_generator()\n",
    "score(sample_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** 0 - not satisfied. 1 - satisfied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 AI function storing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------  ----  --------\nMETA_PROP NAME      TYPE  REQUIRED\nNAME                str   Y\nDESCRIPTION         str   N\nRUNTIME_UID         str   N\nINPUT_DATA_SCHEMA   dict  N\nOUTPUT_DATA_SCHEMA  dict  N\nTAGS                list  N\n------------------  ----  --------\n"
     ]
    }
   ],
   "source": [
    "client.repository.FunctionMetaNames.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No RUNTIME_UID passed. Creating default runtime... SUCCESS\n\nSuccessfully created default runtime with uid: 868da904-8112-48e9-84ff-c3b5907b57e2\n"
     ]
    }
   ],
   "source": [
    "meta_data = {\n",
    "    client.repository.FunctionMetaNames.NAME: 'CARS4U - Satisfaction Prediction - AI Function',\n",
    "}\n",
    "\n",
    "function_details = client.repository.store_function(meta_props=meta_data, function=score_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  ----------------------------------------------------------  ------------------------  ------\nGUID                                  NAME                                                        CREATED                   TYPE\n1e63cc8f-bf92-4b5b-a160-3dae7662dfa7  CARS4U - Satisfaction Prediction - AI Function              2018-08-10T20:47:11.842Z  python\nc9f0eae6-d539-48b7-9862-f784fd7feddb  CARS4U - Business area and Action Prediction - AI Function  2018-08-10T20:44:29.188Z  python\n------------------------------------  ----------------------------------------------------------  ------------------------  ------\n"
     ]
    }
   ],
   "source": [
    "client.repository.list_functions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 AI function deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '1e63cc8f-bf92-4b5b-a160-3dae7662dfa7' started\n\n#######################################################################################\n\n\nINITIALIZING\nDEPLOY_IN_PROGRESS.\nDEPLOY_SUCCESS\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='9ae79113-0075-4dd8-b7a5-805c9704ee7e'\n------------------------------------------------------------------------------------------------\n\n\n"
     ]
    }
   ],
   "source": [
    "function_uid = client.repository.get_function_uid(function_details)\n",
    "\n",
    "function_deployment_details = client.deployments.create(artifact_uid=function_uid, name='CARS4U - Satisfaction Prediction - AI Function Deployment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score AI function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://us-south.ml.cloud.ibm.com/v3/wml_instances/1e60cd60-afdd-4caa-b37a-b028116820ff/deployments/9ae79113-0075-4dd8-b7a5-805c9704ee7e/online\n"
     ]
    }
   ],
   "source": [
    "ai_function_scoring_endpoint = client.deployments.get_scoring_url(function_deployment_details)\n",
    "\n",
    "print(ai_function_scoring_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.deployments.score(ai_function_scoring_endpoint, sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fields': ['prediction', 'prediction_classes', 'probability'], 'values': [[[0.877637], [0], [0.877637]], [[0.623983], [1], [0.623983]], [[0.5], [0], [0.5]], [[0.4733937978744507], [0], [0.4733937978744507]], [[0.7068807482719421], [1], [0.7068807482719421]]]}\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "mimetype": "text/x-python",
   "nbconvert_exporter": "python",
   "version": "3.5.5",
   "name": "python",
   "file_extension": ".py",
   "pygments_lexer": "ipython3",
   "codemirror_mode": {
    "version": 3,
    "name": "ipython"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
